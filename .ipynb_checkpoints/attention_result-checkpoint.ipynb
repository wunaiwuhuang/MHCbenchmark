{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "758420b8-4036-49f0-850d-d941fb68909b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:19:47.847387Z",
     "iopub.status.busy": "2024-12-15T08:19:47.846846Z",
     "iopub.status.idle": "2024-12-15T08:20:03.631701Z",
     "shell.execute_reply": "2024-12-15T08:20:03.629746Z",
     "shell.execute_reply.started": "2024-12-15T08:19:47.847343Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "tools=['mhcflurry_ba','mhcflurry_ps','netmhcpan_ba','netmhcpan_el','bigmhc','capsnetmhc_an','transphla','stmhcpan']\n",
    "pep_len=[8,9,10,11]\n",
    "path_result='/data1/wuguojia/data/mhc_benchmark/attentionbase/result/'\n",
    "# 遍历每个工具\n",
    "for tool in tools:\n",
    "    # 为每个 pep_len 初始化对应的空列表\n",
    "    data_lists = {length: [] for length in pep_len}\n",
    "    tool_path = os.path.join(path_result, tool)\n",
    "    npy_files = [f for f in os.listdir(tool_path) if f.endswith('.npy')]\n",
    "    # 遍历每个文件\n",
    "    for npy_file in npy_files:\n",
    "        parts = npy_file.split('_')\n",
    "        mode=parts[0]\n",
    "        peptide=parts[1]\n",
    "        allele=parts[2]\n",
    "        length=len(peptide)\n",
    "        # 如果肽段的长度在 pep_len 中，处理并加入对应的 data_list\n",
    "        if length in pep_len:\n",
    "            # 读取 .npy 文件的内容\n",
    "            file_path = os.path.join(tool_path, npy_file)\n",
    "            file_data = np.load(file_path)\n",
    "            # 前四列\n",
    "            row_data = [mode, allele, length, peptide]\n",
    "            # 根据 mode 填充 pos 列\n",
    "            if mode == 'LIME':\n",
    "                pos_values = file_data[1:length + 1]  # 取文件数据的第2个数到第length+1个数\n",
    "            elif mode == 'SHAP':\n",
    "                pos_values = file_data[:length]  # 取前 length 个数\n",
    "            # 如果数据不足以填满所有位置，则用 None 或 NaN 补齐\n",
    "            pos_values = list(pos_values) + [None] * (length - len(pos_values))\n",
    "            # 添加 pos 列的数据\n",
    "            row_data.extend(pos_values)\n",
    "            # 添加 tool 列数据\n",
    "            row_data.append(tool)\n",
    "            # 添加 bind_result_tool 和 bind_result_base 列（暂时空缺）\n",
    "            row_data.extend([None, None])\n",
    "            # 将当前行数据添加到对应的长度列表中\n",
    "            data_lists[length].append(row_data)\n",
    "    # 对于每个长度，生成 DataFrame 并保存为 CSV\n",
    "    for length in pep_len:\n",
    "        if data_lists[length]:  # 如果对应长度的列表不为空\n",
    "            columns = ['mode', 'allele', 'length', 'peptide'] + [f'pos_{i+1}' for i in range(length)] + ['tool', 'bind_result_tool', 'bind_result_base']\n",
    "            data_df = pd.DataFrame(data_lists[length], columns=columns)\n",
    "            data_df.to_csv(f'{path_result}{tool}_length_{length}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71d6f6d9-5bae-48a5-a609-c7b081739ae9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-15T08:20:10.245960Z",
     "iopub.status.busy": "2024-12-15T08:20:10.245243Z",
     "iopub.status.idle": "2024-12-15T08:20:14.711110Z",
     "shell.execute_reply": "2024-12-15T08:20:14.710097Z",
     "shell.execute_reply.started": "2024-12-15T08:20:10.245915Z"
    }
   },
   "outputs": [],
   "source": [
    "# this part aims to add bind_result data\n",
    "path_test_use='/data1/wuguojia/data/mhc_benchmark/attentionbase/testdata_use/'\n",
    "test_files = [f for f in os.listdir(path_test_use) if f.endswith('.csv')]\n",
    "test_list = []\n",
    "for test_file in test_files:\n",
    "    file_path = os.path.join(path_test_use, test_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    test_list.append(df)\n",
    "test_df = pd.concat(test_list, ignore_index=True)#get test data matrix\n",
    "\n",
    "result_files=[f for f in os.listdir(path_result) if f.endswith('.csv')]\n",
    "for result_file in result_files:\n",
    "    tool = result_file.split('_length')[0]  # 取文件名中 '_length' 之前的部分作为 tool\n",
    "    file_path=os.path.join(path_result, result_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    # 遍历 df 的每一行，更新 bind_result_base 和 bind_result_tool 列\n",
    "    for i, row in df.iterrows():\n",
    "        # 检查 allele 和 peptide 列是否与 test_df 中 hlatype 和 antigen_peptide 列匹配\n",
    "        match = (test_df['hlatype'] == row['allele']) & (test_df['antigen_peptide'] == row['peptide'])\n",
    "        # 如果匹配，更新该行的 bind_result_base 和 bind_result_tool 列\n",
    "        if match.any():  # 确保有匹配的行\n",
    "            # 取出匹配的行对应的 bind_result\n",
    "            bind_result_value = test_df.loc[match, 'bind_result'].values[0]\n",
    "            tool_value = test_df.loc[match, tool].values[0]\n",
    "            # 更新 df 中的 bind_result_base 和 bind_result_tool 列\n",
    "            df.at[i, 'bind_result_base'] = bind_result_value\n",
    "            df.at[i, 'bind_result_tool'] = tool_value  # tool 定义为从文件名中提取的部分\n",
    "    # 对 df 按照 mode, allele, bind_result_base 列进行排序\n",
    "    df = df.sort_values(by=['mode', 'allele', 'bind_result_base'])\n",
    "    df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97873adc-955d-4e89-9ff9-a71f7f836c41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-05T09:21:22.201740Z",
     "iopub.status.busy": "2024-11-05T09:21:22.201141Z",
     "iopub.status.idle": "2024-11-05T09:21:22.297936Z",
     "shell.execute_reply": "2024-11-05T09:21:22.296967Z",
     "shell.execute_reply.started": "2024-11-05T09:21:22.201682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stmhcpan_length_9.csv\n",
      "Empty DataFrame\n",
      "Columns: [mode, allele, count]\n",
      "Index: []\n",
      "mhcflurry_ps_length_9.csv\n",
      "Empty DataFrame\n",
      "Columns: [mode, allele, count]\n",
      "Index: []\n",
      "bigmhc_length_9.csv\n",
      "Empty DataFrame\n",
      "Columns: [mode, allele, count]\n",
      "Index: []\n",
      "transphla_length_9.csv\n",
      "Empty DataFrame\n",
      "Columns: [mode, allele, count]\n",
      "Index: []\n",
      "netmhcpan_el_length_9.csv\n",
      "Empty DataFrame\n",
      "Columns: [mode, allele, count]\n",
      "Index: []\n",
      "netmhcpan_ba_length_9.csv\n",
      "Empty DataFrame\n",
      "Columns: [mode, allele, count]\n",
      "Index: []\n",
      "capsnetmhc_an_length_9.csv\n",
      "Empty DataFrame\n",
      "Columns: [mode, allele, count]\n",
      "Index: []\n",
      "mhcflurry_ba_length_9.csv\n",
      "Empty DataFrame\n",
      "Columns: [mode, allele, count]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "#this part aims to check unproduced data\n",
    "result_files=[f for f in os.listdir(path_result) if f.endswith('.csv')]\n",
    "for result_file in result_files:\n",
    "    print(result_file)\n",
    "    file_path=os.path.join(path_result, result_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    grouped_counts = df.groupby(['mode', 'allele']).size().reset_index(name='count')\n",
    "    # 过滤出行数小于 100 的结果\n",
    "    filtered_counts = grouped_counts[grouped_counts['count'] < 100]\n",
    "    \n",
    "    # 打印结果\n",
    "    print(filtered_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9248d9bf-808b-412e-9f58-fec6dc4c81e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T05:45:11.126019Z",
     "iopub.status.busy": "2024-10-25T05:45:11.125414Z",
     "iopub.status.idle": "2024-10-25T05:45:11.134163Z",
     "shell.execute_reply": "2024-10-25T05:45:11.133364Z",
     "shell.execute_reply.started": "2024-10-25T05:45:11.125983Z"
    }
   },
   "outputs": [],
   "source": [
    "#prepare prediction\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import pickle, importlib\n",
    "import argparse\n",
    "import subprocess\n",
    "import sys\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "import shap\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f652ef1e-5219-4a4b-960d-4eadf674b2db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T05:45:13.730937Z",
     "iopub.status.busy": "2024-10-25T05:45:13.730280Z",
     "iopub.status.idle": "2024-10-25T05:45:13.946720Z",
     "shell.execute_reply": "2024-10-25T05:45:13.945354Z",
     "shell.execute_reply.started": "2024-10-25T05:45:13.730905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [mode, tool, test_path, train_path, position]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# this part aims to add lack data in attentionbase\n",
    "import os\n",
    "import pandas as pd\n",
    "#get test data matrix\n",
    "path_test_use='/data1/wuguojia/data/mhc_benchmark/attentionbase/testdata_use/'\n",
    "test_files = [f for f in os.listdir(path_test_use) if f.endswith('.csv')]\n",
    "test_list = []\n",
    "for test_file in test_files:\n",
    "    file_path = os.path.join(path_test_use, test_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    test_list.append(df)\n",
    "test_df = pd.concat(test_list, ignore_index=True)\n",
    "df1=test_df[['hlatype','antigen_peptide','antigen_peptide_length']]\n",
    "#get result data matrix\n",
    "path_result='/data1/wuguojia/data/mhc_benchmark/attentionbase/result/'\n",
    "result_files=[f for f in os.listdir(path_result) if f.endswith('.csv')]\n",
    "df_list = [pd.read_csv(os.path.join(path_result, file)) for file in result_files]\n",
    "merged_df = pd.concat(df_list, ignore_index=True)\n",
    "df2=merged_df[['mode', 'allele', 'peptide', 'tool']]\n",
    "#find lack data\n",
    "all_results = []\n",
    "for mode in df2['mode'].unique():\n",
    "    for tool in df2['tool'].unique():\n",
    "        df3 = df2[(df2['mode'] == mode) & (df2['tool'] == tool)]\n",
    "        df3_renamed = df3.rename(columns={'allele': 'hlatype', 'peptide': 'antigen_peptide'})\n",
    "        merged_df = pd.merge(df1, df3_renamed, on=['hlatype', 'antigen_peptide'], how='left', indicator=True)\n",
    "        df1_extra = merged_df[merged_df['_merge'] == 'left_only']\n",
    "        result = df1_extra[['hlatype', 'antigen_peptide']]\n",
    "        result['mode']=mode\n",
    "        result['tool']=tool\n",
    "        result['length'] = result['antigen_peptide'].apply(len)\n",
    "        result['hlatype_length'] = result['hlatype'] + '_' + result['length'].astype(str)\n",
    "        result['position'] = None\n",
    "        result['test_path']=None\n",
    "        result['train_path']=None\n",
    "        for i, row in result.iterrows():\n",
    "            hlatype_length = row['hlatype_length']\n",
    "            antigen_peptide = row['antigen_peptide']\n",
    "            file_path = os.path.join(path_test_use, hlatype_length+'.csv')\n",
    "            df = pd.read_csv(file_path)\n",
    "            position = df[df['antigen_peptide'] == antigen_peptide].index.tolist()\n",
    "            result.at[i, 'position'] = position[0]\n",
    "            result.at[i, 'test_path'] = file_path\n",
    "            #add train path\n",
    "            path_train='/data1/wuguojia/data/mhc_benchmark/attentionbase/traindata_raw/'\n",
    "            if mode=='LIME':\n",
    "                result.at[i,'train_path']=os.path.join(path_train, hlatype_length+'.csv')\n",
    "            if mode=='SHAP':\n",
    "                result.at[i,'train_path']=os.path.join(path_train, hlatype_length+'.pkl')\n",
    "        result=result[['mode','tool','test_path','train_path','position']]\n",
    "        all_results.append(result)\n",
    "result = pd.concat(all_results, ignore_index=True)\n",
    "pd.set_option('display.max_colwidth', None)  # 不限制列宽，显示所有内容\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5563c4bc-f869-4989-8df7-374a7b9c96f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-25T05:43:28.866529Z",
     "iopub.status.busy": "2024-10-25T05:43:28.866004Z",
     "iopub.status.idle": "2024-10-25T05:44:32.119192Z",
     "shell.execute_reply": "2024-10-25T05:44:32.117953Z",
     "shell.execute_reply.started": "2024-10-25T05:43:28.866492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP binding affinity done for index: 0\n"
     ]
    }
   ],
   "source": [
    "# 遍历 result 数据框的每一行\n",
    "for index, row in result.iterrows():\n",
    "    # 设置命令参数\n",
    "    command = [\n",
    "        \"python\", \"/home/wuguojia/biocode/mhc_benchmark/MHCXAI.py\",\n",
    "        \"--input_list\", row['test_path'],\n",
    "        \"--index\", str(row['position']),\n",
    "        \"--predictor\", \"mhcflurry\",\n",
    "        \"--xai\", row['mode'],\n",
    "        \"--mode\", \"affinity\" if row['tool'] == \"mhcflurry_ba\" else \"presentation_score\",\n",
    "        \"--trainf_path\", row['train_path'],\n",
    "        \"--dest\", '/data1/wuguojia/data/mhc_benchmark/attentionbase/result/'\n",
    "    ]\n",
    "    # 运行命令\n",
    "    result = subprocess.run(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, universal_newlines=True)\n",
    "    # 打印结果\n",
    "    print(\"SHAP binding affinity done for index:\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7090cf7-52b4-410a-87c7-8a6e64704b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (shaplime)",
   "language": "python",
   "name": "shaplime"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
